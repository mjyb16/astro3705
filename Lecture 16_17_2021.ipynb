{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%pylab inline\n",
    "import numpy.random as random\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up two sets of 15 values from normal distributions, N(0,1) or N(1,1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata=15\n",
    "data1=random.randn(ndata)\n",
    "data2=random.randn(ndata)+1.\n",
    "\n",
    "del A # if we reinitialize, be sure to redo the slow calculation when we get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using the below code box, plot histograms of data1 and data2 with the same binning enforced (don't allow automatic binning); can you see the difference by eye?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate confidence intervals for the mean of each sample.  __Add code to calculate the std. deviation of the mean for each sample, `sigma1` and `sigma2`.__ (Reminder: _sample_ std. deviation is `np.std` with `ddof=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1=np.mean(data1)\n",
    "mean2=np.mean(data2)\n",
    "\n",
    "sigma1=??? # want the standard deviation of the mean of data1\n",
    "sigma2=??? # want the standard deviation of the mean of data2\n",
    "\n",
    "\n",
    "print(f'means: {mean1:.4f}, {mean2:.4f}')\n",
    "print(f'sigmas {sigma1:.4f} {sigma2:.4f}'')\n",
    "\n",
    "tfactor=stats.t.ppf(1-0.025,ndata-1)\n",
    "print('Confidence Interval 1: ',mean1-tfactor*sigma1,mean1+tfactor*sigma1)\n",
    "print('Confidence Interval 2: ',mean2-tfactor*sigma2,mean2+tfactor*sigma2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now, determine a confidence interval for the difference between the two means, applying propagation of errors.__  Note that the tfactor is not the same as the previous case.  In comparing two samples of size $n_1$ and $n_2$, the t statistic for the difference will be distributed as a t distribution with ($n_1$+$n_2$-2) degrees of freedom\n",
    "\n",
    "\n",
    "__Discuss: Does the confidence interval you derive include 0?__  \n",
    "\n",
    "__Also estimate a 95% upper limit on $\\mu_2 - \\mu_1$ (= (mean difference) - tfactor * (std. dev. of mean difference), but setting the tfactor for a 1-sided limit.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff=???\n",
    "sigma_diff=???\n",
    "tfactor=stats.t.ppf(1-0.025, 2*ndata-2)\n",
    "print('2-sided Confidence Interval: ',???,???)\n",
    "\n",
    "tfactor=stats.t.ppf(1-0.05, 2*ndata-2)\n",
    "print('1-sided Confidence Interval / Upper Limit: ',???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to take a break!\n",
    "\n",
    "We'll stop here for now so we can discuss more things.  If you have extra time:\n",
    "\n",
    "- Try making different realizations of your datasets by rerunning all the cells above and see how the confidence intervals change, how often they include 0, etc.\n",
    "\n",
    "- make `ndata` larger or smaller and see how your confidence intervals and ability to reject the null hypothesis of zero difference changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Bayesian probability that $\\mu_2 > \\mu_1$\n",
    "\n",
    "First, we calculate the array $A = {1\\over 2}(\\Sigma (x_{i} - u)^2 +\\Sigma (y_{i}- (u+v))^2)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only set up the A array if we haven't calculated it before -- this can be slow.\n",
    "\n",
    "try:\n",
    "    A\n",
    "except NameError:    \n",
    "# set up grid in u and v: nbin values from -5 to +5\n",
    "    nbin=501\n",
    "    u = np.linspace(-5.,5.,nbin)\n",
    "    v = np.copy(u)\n",
    "    A=np.zeros((nbin,nbin))\n",
    "    \n",
    "    # calculate A on grid.  i = index in u array; j = index in v array.\n",
    "    for i in arange(nbin):\n",
    "        for j in arange(nbin):\n",
    "            A[j,i]=(np.sum((data1-u[i])**2)+np.sum((data2-u[i]-v[j])**2))/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we calculate $p(u,v) = 2\\, \\Gamma(n)\\, A^{-n}$.\n",
    "\n",
    "__Change the 0 to a 1 in `if 0` below to get the bokeh display to show. Then explore the array p(u,v).  Identify where it peaks, and estimate the corresponding values of u and v.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EqHistColorMapper' from 'bokeh.models.mappers' (/mnt/sda5/anaconda3/lib/python3.7/site-packages/bokeh/models/mappers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5979a07a518b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# do imports for bokeh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearColorMapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLogColorMapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEqHistColorMapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'EqHistColorMapper' from 'bokeh.models.mappers' (/mnt/sda5/anaconda3/lib/python3.7/site-packages/bokeh/models/mappers.py)"
     ]
    }
   ],
   "source": [
    "# calculate probability p(u,v) from A\n",
    "\n",
    "from scipy.special import gamma\n",
    "prob_uv=2*gamma(ndata)*A**(-ndata)  \n",
    "\n",
    "# Explore p(u,v).  u is the x axis here, v is the y axis.\n",
    "\n",
    "# do imports for bokeh\n",
    "from bokeh.plotting import figure, output_file, show, output_notebook\n",
    "from bokeh.models.mappers import LinearColorMapper,LogColorMapper,EqHistColorMapper\n",
    "\n",
    "if 0:\n",
    "# put the plot in this notebook\n",
    "    output_notebook()\n",
    "\n",
    "# set up tooltips so we can read off values at the cursor\n",
    "    p = figure(tooltips=[(\"u\", \"$x\"), (\"v\", \"$y\"), (\"value\", \"@image\")])\n",
    "    p.x_range.range_padding = p.y_range.range_padding = 0\n",
    "\n",
    "# You could instead try the linear or log color mappers\n",
    "    color_mapper = LogColorMapper(palette=\"Turbo256\", low=prob_uv.min(), high=prob_uv.max())\n",
    "\n",
    "# set up the image display, with axis ranges from -5 to +5 \n",
    "    p.image(image=[prob_uv], x=-5, y=-5, dw=10, dh=10, level=\"image\",color_mapper=color_mapper)\n",
    "\n",
    "# show the image, interactively\n",
    "    show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can marginalize to get $p(v) = \\int p(u,v) du$ and $p(u) = \\int p(u,v) dv$.  We can approximate the integrals by sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate marginalized probabilities: p(u) and p(v).  \n",
    "# Note our array is given as p[v,u]; so summing over axis 0 sums over v!!!\n",
    "# we make sure both curves have the same integral by dividing by the overall sum.\n",
    "# We really should multiply by dx so they integrate to 1, but that doesn't matter for anything we do.\n",
    "\n",
    "prob_u=np.sum(prob_uv,axis=0)\n",
    "prob_u=prob_u/np.sum(prob_u)\n",
    "\n",
    "prob_v=np.sum(prob_uv,axis=1)\n",
    "prob_v=prob_v/np.sum(prob_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using the below code box, plot p(u) and p(v), specifying plot styles or labelling them and using `plt.legend` so you can tell which is which.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the Bayesian posterior probability that v>=0 and the corresponding odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate posterior probability and odds that v>0\n",
    "\n",
    "wh_gt=np.where(v >= 0)\n",
    "p_gt_0=np.sum(prob_v[wh_gt])\n",
    "\n",
    "wh_lt=np.where(v <= 0)\n",
    "p_lt_0=np.sum(prob_v[wh_lt])\n",
    "\n",
    "# this is a cheat to handle the fact that we included the value at 0 in the summation:\n",
    "p_gt_0 = p_gt_0/(p_gt_0+p_lt_0)\n",
    "\n",
    "# probability that p>0, as well as odds in favor of that \n",
    "print(p_gt_0,p_gt_0/(1-p_gt_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare the results to the frequentist confidence interval: change the value of `signif` in the code box below until your confidence interval barely excludes 0 to see what significance v<0 is excluded at.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif=0.05\n",
    "tfactor=stats.t.ppf(1-signif/2, 2*ndata-2)\n",
    "sigma_diff=np.sqrt(sigma1**2+sigma2**2)\n",
    "\n",
    "print('2-sided Confidence Interval: ',(mean2-mean1)-tfactor*sigma_diff,(mean2-mean1)+tfactor*sigma_diff)\n",
    "\n",
    "tfactor=stats.t.ppf(1-signif, 2*ndata-2)\n",
    "print('1-sided Confidence Interval/Upper Limit : ',(mean2-mean1)-tfactor*sigma_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The likelihood ratio test\n",
    "\n",
    "A frequentist method with greater statistical power is to evaluate the ratio of the maximum likelihood under $H_0$ and $H_1$, $\\Lambda$.  $-2\\ln{\\Lambda}$ should be distributed as a $\\chi^2$ random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_0=np.where(v == 0)\n",
    "wh_gt=np.where(v > 0)\n",
    "likelihood_ratio=np.max(prob_uv[wh_0,:])/np.max(prob_uv[wh_gt,:])\n",
    "\n",
    "print('-2 ln of ratio: {:.2f}'.format(-2*np.log(likelihood_ratio)))\n",
    "print('alpha = 0.05 minimum chi-squared: {:.2f}'.format(stats.chi2.ppf(1-0.05,1)))\n",
    "print('p-value: {:.2e}'.format((1-stats.chi2.cdf(-2*np.log(likelihood_ratio),1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The t test\n",
    "\n",
    "The classical statistical test for checking if two datasets have the same mean is the t test, which uses a statistic similar to the t we've encountered before.  We calculate the t statistic for the difference of the means of the two datasets; it should follow a t distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hard way:\n",
    "# s=sqrt (((ndata-1.)*sigma1**2*ndata + (ndata-1.)*sigma2**2*ndata)/(2*ndata-2.)*(2./ndata))\n",
    "\n",
    "# the easy way, since nx=ny:\n",
    "sigma1=np.std(data1,ddof=1)/np.sqrt(ndata)\n",
    "sigma2=np.std(data2,ddof=1)/np.sqrt(ndata)\n",
    "\n",
    "s=np.sqrt(sigma1**2+sigma2**2)\n",
    "t=(mean2-mean1)/s   # calculate t statistic\n",
    "print('Value of t: {:.2f}'.format(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating cutoffs and p values\n",
    "\n",
    "For a two-sided test, we divide our rejection region between the two tails of the distribution.  We can again use `stats.t.ppf()` to determine cutoffs in t corresponding to our threshold for signficance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif=0.05\n",
    "print(stats.t.ppf(1-signif/2, 2*ndata-2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using the below code box, calculate the cutoff in t for a one-tailed test, where we are checking if mean2 is > mean1, without considering a lower value a possibility.__  This is more analogous to our Bayesian test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating p-values\n",
    "\n",
    "We can calculate a p-value for our value of t using `stats.t.cdf()`.  Note that we want the probability of getting the observed value of t _or greater_; the CDF integrates from -infinity to x.  \n",
    "\n",
    "__Using the below code box, calculate the p-value for our value of t for a one-sided test.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save all this work by using `stats.ttest_ind`.  It will only do a two-tailed test, though it can relax the assumption of equal sigmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these turn out to be the same if data2 & data1 have the same size, but in general that doesn't need to be the case.\n",
    "# it returns a tuple of the t statistic and the p-value.\n",
    "\n",
    "print(stats.ttest_ind(data2,data1))\n",
    "\n",
    "print(stats.ttest_ind(data2,data1,equal_var = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you have extra time...\n",
    "\n",
    "- Try making different realizations of your datasets by rerunning all the cells above and see how the confidence intervals change, how often they include 0, etc.\n",
    "\n",
    "- make `ndata` larger or smaller and see how your confidence intervals and ability to reject the null hypothesis of zero difference changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
