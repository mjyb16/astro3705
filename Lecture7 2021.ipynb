{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import various modules we've been using\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy.random as random\n",
    "import scipy.interpolate as interpol\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial distributions for small $p$\n",
    "\n",
    "Let's plot the distribution of expected accidents in Pittsburgh per day, either calculating from the number of accidents per minute or per second.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb,factorial\n",
    "\n",
    "x=np.arange(25)\n",
    "\n",
    "events_from_minutes=comb(1440,x)*2.85E-3**x*(1-2.85E-3)**(1440-x)\n",
    "\n",
    "events_from_seconds=comb(86400,x)*4.75E-5**x*(1-4.75E-5)**(86400-x)\n",
    "poisson=4.1**x * exp(-4.1)/factorial(x)\n",
    "\n",
    "# provide the label= keyword to make curves show up in the legend\n",
    "plt.plot(x,events_from_minutes,'ro',label='Minutes')\n",
    "plt.plot(x,events_from_seconds,'b-',label='Seconds')\n",
    "\n",
    "plt.xlabel('Number of accidents')\n",
    "plt.ylabel('Fraction')\n",
    "\n",
    "# cause the legend to be drawn\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Poisson distribution\n",
    "\n",
    "The probability of k occurrences from a poisson distribution of mean $\\lambda$ is given by $p(k) = {{\\lambda^k \\exp(-\\lambda)} \\over {k!}}$ .\n",
    "\n",
    "__Using the below code box, plot Poisson distributions for $\\lambda$ = 1, 4, and 10 and k ranging from 0 to 25; label all curves and add a legend.__  You may want to use `scipy.stats.poisson` for convenience; otherwise you will need to use the `factorial` function (imported at the top of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: lambda = 1\n",
    "k = np.arange(25)\n",
    "# we shouldn't use lambda as a variable name as it is a Python keyword (which we will use later...)\n",
    "lambdap=1.\n",
    "plt.plot(k,lambdap**k*np.exp(-lambdap)/factorial(k),'r.',label=r'$\\lambda$ = 1')\n",
    "\n",
    "#for different marker options see: https://matplotlib.org/api/markers_api.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymmetry of the Poisson distribution\n",
    "\n",
    "We can never observe fewer than zero events.  As a result, the Poisson distribution is very asymmetric when $\\lambda$ is small.  How low does $\\lambda$ need to be for this to be a big issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=np.linspace(0.,10.,101)\n",
    "plt.plot(x,x**0*exp(-x)/factorial(0))\n",
    "plt.xlabel(r'$\\lambda$ = Mean of Poisson distribution',size='large')\n",
    "plt.ylabel('Probability of zero events',size='large')\n",
    "\n",
    "# Try this code box with and without the following line commented out:\n",
    "#plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priors for the Poisson distribution\n",
    "\n",
    "Jeffreys prior: $p(\\lambda) \\propto \\lambda^{-1/2}$\n",
    "\n",
    "The below code plots the likelihood & posterior for the Poisson parameter $\\lambda$ if $N=1$ events are observed.  __Replot the curves for cases where N = 3, 5, or 10 events were seen (just modify the code, don't add more curves).__  \n",
    " \n",
    "__Evaluate how both the peak of the likelihood and posterior correspond to the observed # of events, N, in each case (indicated via the dashed red curve).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "# set up an array of possible lambda values\n",
    "lam_arr=np.linspace(0,25,251)+1.E-3\n",
    "\n",
    "# this is the observed number of events\n",
    "N=1\n",
    "\n",
    "# Jeffreys prior: 1/sqrt(lambda)\n",
    "likelihood = lam_arr**(N)*np.exp(-lam_arr)\n",
    "posterior = lam_arr**(N-0.5)*np.exp(-lam_arr)\n",
    "\n",
    "\n",
    "# Note: We are making the maximum 1 for convenience, but these are not being normalized into PDFs.\n",
    "plt.plot(lam_arr,posterior/np.max(posterior),label='Posterior')\n",
    "plt.plot(lam_arr,likelihood/np.max(likelihood),label='Likelihood')\n",
    "plt.xlabel(r'$\\lambda$',size='x-large')\n",
    "plt.ylabel(r'$p(\\lambda)$',size='x-large')\n",
    "\n",
    "#draw a vertical line at N.  How do the peak of the likelihood and posterior compare to the observed # of events?\n",
    "plt.axvline(N,color='red',ls='--',lw=1,label='Observed N')\n",
    "\n",
    "plt.legend(fontsize='large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Gaussian distribution\n",
    "\n",
    "Let's explore what happens when we change parameters of the Gaussian distribution, \n",
    "$f(x) = {1 \\over \\sqrt{2 \\pi \\sigma^2}} e^{-(x-\\mu)^2 \\over 2\\sigma^2}$.\n",
    "\n",
    "  __Try changing mu to a few different values in the code below.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(-10,10,20001)\n",
    "mu=0.\n",
    "sigma=1.\n",
    "plt.plot(x,1/np.sqrt(2*np.pi*sigma**2)*exp(-(x-mu)**2/2./sigma**2))\n",
    "mu=1\n",
    "plt.plot(x,1/np.sqrt(2*np.pi*sigma**2)*exp(-(x-mu)**2/2./ sigma**2),'g--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the value of sigma\n",
    "\n",
    "__In the below code box, define variables y2, using sigma=2, and y0_2, using sigma=0.2; plot up all 3 curves (y1,y0_2,y2) together in the same plot.__\n",
    "\n",
    "__Then try making the y axis logarithmic (how do we do that?)  and explain what you see.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=0.\n",
    "sigma=1.\n",
    "y1=1/np.sqrt(2*np.pi*sigma**2)*exp(-(x-mu)**2/2./sigma**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Gaussian integrals\n",
    "\n",
    "We expect probability 0.68268949 for being between -1 sigma to +1 sigma, probability 0.95449974 between -2 sigma and +2 sigma.  __Do we find the same from numerical integration?__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(-25,25,501)\n",
    "mu=0.\n",
    "sigma=1.\n",
    "y1=1/np.sqrt(2*np.pi*sigma**2)*exp(-(x-mu)**2/2./sigma**2)\n",
    "\n",
    "interp_1=interpol.interp1d(x,y1,kind='cubic') \n",
    "\n",
    "print(f'integrals for standard Gaussian: \\\n",
    " {integrate.quad(interp_1,-1.,1.,epsrel=1.e-4)[0]:.8f}, \\\n",
    " {integrate.quad(interp_1,-2.,2.,epsrel=1.e-4)[0]:.8f}')\n",
    "\n",
    "mu=0.\n",
    "sigma=10.\n",
    "y10=1/np.sqrt(2*np.pi*sigma**2)*exp(-(x-mu)**2/2./sigma**2)\n",
    "\n",
    "interp_10=interpol.interp1d(x,y10,kind='cubic') \n",
    "\n",
    "print(f'integrals for sigma=10 Gaussian: \\\n",
    " {integrate.quad(interp_10,-10.,10.,epsrel=1.e-4)[0]:.8f}, \\\n",
    " {integrate.quad(interp_10,-20.,20.,epsrel=1.e-4)[0]:.8f}')\n",
    "\n",
    "print('Expected values:                  0.68268949,  0.95449974')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Gaussian random variables \n",
    "\n",
    "We can generate Gaussian random variables with mean 0 and sigma 1 using the function `numpy.random.randn()`, which works just like `numpy.random.rand()`.\n",
    "\n",
    "__Repeatedly execute the following code, and see how your histograms change.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as random\n",
    "bin_array=np.linspace(-5.,5.,501)\n",
    "nrandom=int(1E4)\n",
    "n,bins,patches=plt.hist(random.randn(nrandom),bins=bin_array,histtype='step') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In the below code box, make a histogram from Gaussian random data drawn from the distribution N(5,$5^2$) (i.e, with mu=5 and sigma=5).__  Recall that since the center shifts with $\\mu$ and the width is proportional to $\\sigma$, we can get numbers distributed as $N(\\mu,\\sigma^2)$ by transforming random values from the standard normal distribution. I.e. we generate a value $x'$ from $N(\\mu,\\sigma^2)$ by \n",
    "\n",
    "$x'= \\sigma x + \\mu$,\n",
    "\n",
    "where $x$ is a random variable distributed as $N(0,1)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bayesian Analysis of Gaussian data\n",
    "\n",
    "Suppose we have some measured value for x, where we expect x to come from a Gaussian of some unknown $\\mu$, but with known $\\sigma=2$, i.e., N($\\mu$,2$^2$).\n",
    "\n",
    "__What is the posterior for $\\mu$ given a single measurement (say, x=5), using the Jeffreys prior prob($\\mu$) = 1?__  Fill in the missing pieces below!!!\n",
    "\n",
    "Reminder: the formula for a Gaussian is $f(x) = { 1 \\over {\\sqrt{2 \\pi \\sigma^2}}} {\\rm exp}(-{ {(x-\\mu)^2} \\over {2 \\sigma^2}})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=5\n",
    "sigma=2.\n",
    "\n",
    "mu=np.linspace(-10.,10.,201)\n",
    "\n",
    "# Fill in the likelihood below: what is p(x | mu)? \n",
    "likelihood = ???\n",
    "\n",
    "# Fill in the prior; we want a uniform prior, same size as the mu array, with value 1 everywhere\n",
    "prior= ???    \n",
    "plt.plot(mu,likelihood,label='Likelihood')\n",
    "plt.plot(mu,likelihood*prior,label='Posterior')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Analysis for $\\sigma$\n",
    "\n",
    "- Now suppose we have some measured value for x, where we expect x to come from a Gaussian of known mean $\\mu=0$, but with unknown $\\sigma$.\n",
    "\n",
    "- __What is the likelihood for $\\sigma$ and posterior for $\\sigma$ given a single measurement (say, x=5), with prior prob($\\sigma$) = 1/$\\sigma$?__\n",
    "\n",
    "  \n",
    "__This time, be sure to normalize the posterior distribution to have integral 1.__  Recall that we used `interpol.interp1d` and `scipy.integrate.quad` for integration before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=5\n",
    "mu=0.\n",
    "sigma=np.linspace(0.,50.,501)+1.E-3 # want to avoid dividing 1/0\n",
    "likelihood=???\n",
    "prior = ???\n",
    "norm = ???\n",
    "\n",
    "plt.plot(sigma,likelihood,label='Likelihood') \n",
    "plt.plot(sigma,likelihood*prior/norm,label='Posterior')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you have extra time\n",
    "\n",
    "__Calculate the likelihood and Bayesian posterior for the variance $V = \\sigma^2$.  Normalize your curves to peak at 1.__  The Jeffreys prior for variance of a Gaussian is $p(V)=1/V$.  How does your estimate for V compare to your estimate for $\\sigma$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
