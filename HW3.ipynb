{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats as stats\n",
    "import astropy.stats as astats\n",
    "import numpy.random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hlmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode2(data,**kwargs):\n",
    "# note: provide bins and (optionally) range keywords to not use\n",
    "# defaults of np.histogram (10 bins, full range)\n",
    "    counts,edges=np.histogram(data,**kwargs)\n",
    "    whmax=np.argmax(counts)\n",
    "    mode=(edges[whmax]+edges[whmax+1])/2\n",
    "    return(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1, Part A\n",
    "### Monte Carlo setup\n",
    "\n",
    "Foutlier = 0, ndata = 100 (perfect Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4) # reduced from 5E4 due to some functions not being vectorized, eg hlmean. Still sufficiently large number of simulations.\n",
    "ndata=100\n",
    "foutlier=0\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.randn(nsims,ndata)*200.+4750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(fakedata, axis = 1)\n",
    "medians = np.median(fakedata, axis = 1)\n",
    "modes = [mode2(fakedata0,bins=np.arange(fakedata0.min(),fakedata0.max(),50)) for fakedata0 in fakedata]\n",
    "modes = np.array(modes)\n",
    "hlmeans = [hlmean.hlmean(fakedata0) for fakedata0 in fakedata]\n",
    "hlmeans = np.array(hlmeans)\n",
    "tmeans = [stats.tmean(fakedata0,limits=np.percentile(fakedata0,(10,90))) for fakedata0 in fakedata]\n",
    "tmeans = np.array(tmeans)\n",
    "sclips = []\n",
    "for i in range(0, nsims):\n",
    "    clipped_data,low_threshold,high_threshold =  stats.sigmaclip(fakedata[i],low=3.,high=3.)\n",
    "    sclips += [np.mean(clipped_data)]\n",
    "sclips = np.array(sclips)\n",
    "winsors = [np.mean(stats.mstats.winsorize(fakedata0,limits=(.1,.1))) for fakedata0 in fakedata]\n",
    "winsors = np.array(winsors)\n",
    "biweights = astats.biweight_location(fakedata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected mean: 3150\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Mean: 0.5778\n",
      "Median: -0.1513\n",
      "Mode: -170.0752\n",
      "H-L mean: 0.6586\n",
      "10% Trimmed mean: 0.5588\n",
      "Sigma-clipped: 0.6868\n",
      "Winsorized: 0.7596\n",
      "Biweight: 0.2509\n",
      "\n",
      "SPREAD OF ESTIMATORS:\n",
      "Mean: 93.4153\n",
      "Median: 115.7042\n",
      "Mode: 488.8806\n",
      "H-L mean: 96.3031\n",
      "10% Trimmed mean: 96.1619\n",
      "Sigma-clipped: 94.6896\n",
      "Winsorized: 95.1428\n",
      "Biweight: 99.8122\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected mean: 3150\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.mean(means - 3150):.4f}')\n",
    "print(f'Median: {np.mean(medians - 3150):.4f}')\n",
    "print(f'Mode: {np.mean(modes - 3150):.4f}')\n",
    "print(f'H-L mean: {np.mean(hlmeans - 3150):.4f}')\n",
    "print(f'10% Trimmed mean: {np.mean(tmeans - 3150):.4f}')\n",
    "print(f'Sigma-clipped: {np.mean(sclips - 3150):.4f}')\n",
    "print(f'Winsorized: {np.mean(winsors - 3150):.4f}')\n",
    "print(f'Biweight: {np.mean(biweights - 3150):.4f}')\n",
    "print()\n",
    "print(\"SPREAD OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.std(means):.4f}')\n",
    "print(f'Median: {np.std(medians):.4f}')\n",
    "print(f'Mode: {np.std(modes):.4f}')\n",
    "print(f'H-L mean: {np.std(hlmeans):.4f}')\n",
    "print(f'10% Trimmed mean: {np.std(tmeans):.4f}')\n",
    "print(f'Sigma-clipped: {np.std(sclips):.4f}')\n",
    "print(f'Winsorized: {np.std(winsors):.4f}')\n",
    "print(f'Biweight: {np.std(biweights):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of perfect Gaussian data, if we seek to minimize bias, then Biweight and Median are both good choices, Median being the least biased choice. However, Median is the second highest for spread, and Biweight's spread is lower but still higher than the mean's spread, which is the lowest. Thus, Biweight serves as a compromise between mean and median. Trimmed mean also is less biased than the mean, but not significantly so, and this advantage comes at the cost of a higher spread. All the other statistics are more biased than the mean and have a higher spread. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1, Part B\n",
    "### Monte Carlo setup\n",
    "\n",
    "Foutlier = 0.1, ndata = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4) # reduced from 5E4 due to some functions not being vectorized, eg hlmean. Still sufficiently large number of simulations.\n",
    "ndata=5\n",
    "foutlier=0.1\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.randn(nsims,ndata)*200.+4750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(fakedata, axis = 1)\n",
    "medians = np.median(fakedata, axis = 1)\n",
    "modes = [mode2(fakedata0,bins=np.arange(fakedata0.min(),fakedata0.max(),50)) for fakedata0 in fakedata]\n",
    "modes = np.array(modes)\n",
    "hlmeans = [hlmean.hlmean(fakedata0) for fakedata0 in fakedata]\n",
    "hlmeans = np.array(hlmeans)\n",
    "tmeans = [stats.tmean(fakedata0,limits=np.percentile(fakedata0,(10,90))) for fakedata0 in fakedata]\n",
    "tmeans = np.array(tmeans)\n",
    "sclips = []\n",
    "for i in range(0, nsims):\n",
    "    clipped_data,low_threshold,high_threshold =  stats.sigmaclip(fakedata[i],low=3.,high=3.)\n",
    "    sclips += [np.mean(clipped_data)]\n",
    "sclips = np.array(sclips)\n",
    "winsors = [np.mean(stats.mstats.winsorize(fakedata0,limits=(.1,.1))) for fakedata0 in fakedata]\n",
    "winsors = np.array(winsors)\n",
    "biweights = astats.biweight_location(fakedata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected mean: 3150\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Mean: 160.4358\n",
      "Median: 156.6664\n",
      "Mode: -919.9316\n",
      "H-L mean: 161.7034\n",
      "10% Trimmed mean: 164.1139\n",
      "Sigma-clipped: 160.4358\n",
      "Winsorized: 160.4358\n",
      "Biweight: 161.8702\n",
      "\n",
      "SPREAD OF ESTIMATORS:\n",
      "Mean: 452.5797\n",
      "Median: 578.7716\n",
      "Mode: 713.2324\n",
      "H-L mean: 482.1006\n",
      "10% Trimmed mean: 504.4914\n",
      "Sigma-clipped: 452.5797\n",
      "Winsorized: 452.5797\n",
      "Biweight: 549.6673\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected mean: 3150\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.mean(means - 3150):.4f}')\n",
    "print(f'Median: {np.mean(medians - 3150):.4f}')\n",
    "print(f'Mode: {np.mean(modes - 3150):.4f}')\n",
    "print(f'H-L mean: {np.mean(hlmeans - 3150):.4f}')\n",
    "print(f'10% Trimmed mean: {np.mean(tmeans - 3150):.4f}')\n",
    "print(f'Sigma-clipped: {np.mean(sclips - 3150):.4f}')\n",
    "print(f'Winsorized: {np.mean(winsors - 3150):.4f}')\n",
    "print(f'Biweight: {np.mean(biweights - 3150):.4f}')\n",
    "print()\n",
    "print(\"SPREAD OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.std(means):.4f}')\n",
    "print(f'Median: {np.std(medians):.4f}')\n",
    "print(f'Mode: {np.std(modes):.4f}')\n",
    "print(f'H-L mean: {np.std(hlmeans):.4f}')\n",
    "print(f'10% Trimmed mean: {np.std(tmeans):.4f}')\n",
    "print(f'Sigma-clipped: {np.std(sclips):.4f}')\n",
    "print(f'Winsorized: {np.std(winsors):.4f}')\n",
    "print(f'Biweight: {np.std(biweights):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we should use the mean, since it has the second lowest bias (after the the median) and the lowest spread. Sigma-clipped and winsorized provide no additional benefit over the regular mean in this instance, since they all have the same bias and spread (nothing is clipped or winsorized in the case of such a small sample). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo setup\n",
    "\n",
    "Foutlier = 0.1, ndata = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4) # reduced from 5E4 due to some functions not being vectorized, eg hlmean. Still sufficiently large number of simulations.\n",
    "ndata=100\n",
    "foutlier=0.1\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.randn(nsims,ndata)*200.+4750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(fakedata, axis = 1)\n",
    "medians = np.median(fakedata, axis = 1)\n",
    "modes = [mode2(fakedata0,bins=np.arange(fakedata0.min(),fakedata0.max(),50)) for fakedata0 in fakedata]\n",
    "modes = np.array(modes)\n",
    "hlmeans = [hlmean.hlmean(fakedata0) for fakedata0 in fakedata]\n",
    "hlmeans = np.array(hlmeans)\n",
    "tmeans = [stats.tmean(fakedata0,limits=np.percentile(fakedata0,(10,90))) for fakedata0 in fakedata]\n",
    "tmeans = np.array(tmeans)\n",
    "sclips = []\n",
    "for i in range(0, nsims):\n",
    "    clipped_data,low_threshold,high_threshold =  stats.sigmaclip(fakedata[i],low=3.,high=3.)\n",
    "    sclips += [np.mean(clipped_data)]\n",
    "sclips = np.array(sclips)\n",
    "winsors = [np.mean(stats.mstats.winsorize(fakedata0,limits=(.1,.1))) for fakedata0 in fakedata]\n",
    "winsors = np.array(winsors)\n",
    "biweights = astats.biweight_location(fakedata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected mean: 3150\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Mean: 160.3033\n",
      "Median: 132.4807\n",
      "Mode: -88.7331\n",
      "H-L mean: 162.0580\n",
      "10% Trimmed mean: 169.3545\n",
      "Sigma-clipped: 162.0528\n",
      "Winsorized: 177.4923\n",
      "Biweight: 157.4129\n",
      "\n",
      "SPREAD OF ESTIMATORS:\n",
      "Mean: 101.2232\n",
      "Median: 132.0090\n",
      "Mode: 611.0597\n",
      "H-L mean: 108.8471\n",
      "10% Trimmed mean: 110.3218\n",
      "Sigma-clipped: 101.9459\n",
      "Winsorized: 103.9501\n",
      "Biweight: 112.1591\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected mean: 3150\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.mean(means - 3150):.4f}')\n",
    "print(f'Median: {np.mean(medians - 3150):.4f}')\n",
    "print(f'Mode: {np.mean(modes - 3150):.4f}')\n",
    "print(f'H-L mean: {np.mean(hlmeans - 3150):.4f}')\n",
    "print(f'10% Trimmed mean: {np.mean(tmeans - 3150):.4f}')\n",
    "print(f'Sigma-clipped: {np.mean(sclips - 3150):.4f}')\n",
    "print(f'Winsorized: {np.mean(winsors - 3150):.4f}')\n",
    "print(f'Biweight: {np.mean(biweights - 3150):.4f}')\n",
    "print()\n",
    "print(\"SPREAD OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.std(means):.4f}')\n",
    "print(f'Median: {np.std(medians):.4f}')\n",
    "print(f'Mode: {np.std(modes):.4f}')\n",
    "print(f'H-L mean: {np.std(hlmeans):.4f}')\n",
    "print(f'10% Trimmed mean: {np.std(tmeans):.4f}')\n",
    "print(f'Sigma-clipped: {np.std(sclips):.4f}')\n",
    "print(f'Winsorized: {np.std(winsors):.4f}')\n",
    "print(f'Biweight: {np.std(biweights):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we should use the median, since it has the second lowest bias (after mode) and only slightly higher spread than the mean. The mode, while least biased in this instance, has a much higher spread. While biweight is also less biased than the mean, it is more biased than the median, and has a higher spread than the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo setup\n",
    "\n",
    "Foutlier = 0.1, ndata = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4) # reduced from 5E4 due to some functions not being vectorized, eg hlmean. Still sufficiently large number of simulations.\n",
    "ndata=25\n",
    "foutlier=0.1\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.randn(nsims,ndata)*200.+4750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(fakedata, axis = 1)\n",
    "medians = np.median(fakedata, axis = 1)\n",
    "modes = [mode2(fakedata0,bins=np.arange(fakedata0.min(),fakedata0.max(),50)) for fakedata0 in fakedata]\n",
    "modes = np.array(modes)\n",
    "hlmeans = [hlmean.hlmean(fakedata0) for fakedata0 in fakedata]\n",
    "hlmeans = np.array(hlmeans)\n",
    "tmeans = [stats.tmean(fakedata0,limits=np.percentile(fakedata0,(10,90))) for fakedata0 in fakedata]\n",
    "tmeans = np.array(tmeans)\n",
    "sclips = []\n",
    "for i in range(0, nsims):\n",
    "    clipped_data,low_threshold,high_threshold =  stats.sigmaclip(fakedata[i],low=3.,high=3.)\n",
    "    sclips += [np.mean(clipped_data)]\n",
    "sclips = np.array(sclips)\n",
    "winsors = [np.mean(stats.mstats.winsorize(fakedata0,limits=(.1,.1))) for fakedata0 in fakedata]\n",
    "winsors = np.array(winsors)\n",
    "biweights = astats.biweight_location(fakedata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected mean: 3150\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Mean: 158.4455\n",
      "Median: 134.9621\n",
      "Mode: -346.6831\n",
      "H-L mean: 160.4018\n",
      "10% Trimmed mean: 164.6754\n",
      "Sigma-clipped: 159.0059\n",
      "Winsorized: 170.0312\n",
      "Biweight: 153.6898\n",
      "\n",
      "SPREAD OF ESTIMATORS:\n",
      "Mean: 201.9668\n",
      "Median: 261.3799\n",
      "Mode: 747.7605\n",
      "H-L mean: 215.9766\n",
      "10% Trimmed mean: 219.8671\n",
      "Sigma-clipped: 202.5383\n",
      "Winsorized: 206.8125\n",
      "Biweight: 225.8987\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected mean: 3150\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.mean(means - 3150):.4f}')\n",
    "print(f'Median: {np.mean(medians - 3150):.4f}')\n",
    "print(f'Mode: {np.mean(modes - 3150):.4f}')\n",
    "print(f'H-L mean: {np.mean(hlmeans - 3150):.4f}')\n",
    "print(f'10% Trimmed mean: {np.mean(tmeans - 3150):.4f}')\n",
    "print(f'Sigma-clipped: {np.mean(sclips - 3150):.4f}')\n",
    "print(f'Winsorized: {np.mean(winsors - 3150):.4f}')\n",
    "print(f'Biweight: {np.mean(biweights - 3150):.4f}')\n",
    "print()\n",
    "print(\"SPREAD OF ESTIMATORS:\")\n",
    "print(f'Mean: {np.std(means):.4f}')\n",
    "print(f'Median: {np.std(medians):.4f}')\n",
    "print(f'Mode: {np.std(modes):.4f}')\n",
    "print(f'H-L mean: {np.std(hlmeans):.4f}')\n",
    "print(f'10% Trimmed mean: {np.std(tmeans):.4f}')\n",
    "print(f'Sigma-clipped: {np.std(sclips):.4f}')\n",
    "print(f'Winsorized: {np.std(winsors):.4f}')\n",
    "print(f'Biweight: {np.std(biweights):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the median again proves to be the best due to having the least bias and a comparable, if high, spread. As with the previous case, the mean has a much lower spread, but it is more biased. The biweight mean strikes a compromise between mean and median, erring on the side of more bias and less spread. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2, Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4)\n",
    "ndata=100\n",
    "foutlier=0\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.uniform(low = 0, high = 6500, size = (nsims,ndata))*200.+4750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.std(fakedata, axis = 1)\n",
    "normmeanabsdevs = np.mean(np.abs(fakedata-np.reshape(np.mean(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.7979\n",
    "normmads = np.median(np.abs(fakedata-np.reshape(np.median(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.6745\n",
    "bimidvars = astats.biweight_midvariance(fakedata, axis = 1)\n",
    "iqrs = (np.percentile(fakedata, 75, axis = 1) - np.percentile(fakedata, 25, axis = 1))/1.349\n",
    "tstds = np.array([stats.tstd(fakedata0, limits=(np.percentile(fakedata0, 10),np.percentile(fakedata0, 90))) for fakedata0 in fakedata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected standard deviation: 930\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Standard deviation: -6.2034\n",
      "Average absolute deviation: -4.0455\n",
      "MAD: -5.8634\n",
      "Biweight standard deviation: 3.2727\n",
      "IQR: -11.5846\n",
      "10% Trimmed standard deviation: -309.1215\n",
      "\n",
      "Spread OF ESTIMATORS:\n",
      "Standard deviation: 65.4496\n",
      "Average absolute deviation: 70.1123\n",
      "MAD: 108.5375\n",
      "Biweight standard deviation: 69.0927\n",
      "IQR: 107.3595\n",
      "10% Trimmed standard deviation: 55.4116\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected standard deviation: 930\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.mean(stds - 930):.4f}')\n",
    "print(f'Average absolute deviation: {np.mean(normmeanabsdevs - 930):.4f}')\n",
    "print(f'MAD: {np.mean(normmads - 930):.4f}')\n",
    "print(f'Biweight standard deviation: {np.mean(np.sqrt(bimidvars) - 930):.4f}')\n",
    "print(f'IQR: {np.mean(iqrs - 930):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.mean(tstds - 930):.4f}')\n",
    "print()\n",
    "print(\"Spread OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.std(stds):.4f}')\n",
    "print(f'Average absolute deviation: {np.std(normmeanabsdevs):.4f}')\n",
    "print(f'MAD: {np.std(normmads):.4f}')\n",
    "print(f'Biweight standard deviation: {np.std(np.sqrt(bimidvars)):.4f}')\n",
    "print(f'IQR: {np.std(iqrs):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.std(tstds):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Gaussian case, the Biweight standard deviation has the lowest bias and a fairly similar spread to the standard deviation, making it a good estimator. The average abs standard deviation also outperforms the regular standard deviation when it comes to bias, at the cost of spread. The trimmed standard deviation has a low spread but it is very biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2, Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4)\n",
    "ndata=5\n",
    "foutlier=0.1\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.uniform(low = 0, high = 6500, size = (nsims,ndata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.std(fakedata, axis = 1)\n",
    "normmeanabsdevs = np.mean(np.abs(fakedata-np.reshape(np.mean(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.7979\n",
    "normmads = np.median(np.abs(fakedata-np.reshape(np.median(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.6745\n",
    "bimidvars = astats.biweight_midvariance(fakedata, axis = 1)\n",
    "iqrs = (np.percentile(fakedata, 75, axis = 1) - np.percentile(fakedata, 25, axis = 1))/1.349\n",
    "tstds = np.array([stats.tstd(fakedata0, limits=(np.percentile(fakedata0, 10),np.percentile(fakedata0, 90))) for fakedata0 in fakedata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected standard deviation: 930\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Standard deviation: -39.6606\n",
      "Average absolute deviation: 12.5395\n",
      "MAD: -76.9644\n",
      "Biweight standard deviation: -71.2565\n",
      "IQR: -177.2946\n",
      "10% Trimmed standard deviation: -396.2571\n",
      "\n",
      "Spread OF ESTIMATORS:\n",
      "Standard deviation: 343.4008\n",
      "Average absolute deviation: 368.8269\n",
      "MAD: 511.2933\n",
      "Biweight standard deviation: 409.9788\n",
      "IQR: 439.2326\n",
      "10% Trimmed standard deviation: 311.5564\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected standard deviation: 930\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.mean(stds - 930):.4f}')\n",
    "print(f'Average absolute deviation: {np.mean(normmeanabsdevs - 930):.4f}')\n",
    "print(f'MAD: {np.mean(normmads - 930):.4f}')\n",
    "print(f'Biweight standard deviation: {np.mean(np.sqrt(bimidvars) - 930):.4f}')\n",
    "print(f'IQR: {np.mean(iqrs - 930):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.mean(tstds - 930):.4f}')\n",
    "print()\n",
    "print(\"Spread OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.std(stds):.4f}')\n",
    "print(f'Average absolute deviation: {np.std(normmeanabsdevs):.4f}')\n",
    "print(f'MAD: {np.std(normmads):.4f}')\n",
    "print(f'Biweight standard deviation: {np.std(np.sqrt(bimidvars)):.4f}')\n",
    "print(f'IQR: {np.std(iqrs):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.std(tstds):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the average absolute deviation has a far lower bias, so it is the best choice for measuring velocity dispersion, even if the standard deviation and trimmed std have a slightly lower spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4)\n",
    "ndata=25\n",
    "foutlier=0.1\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.uniform(low = 0, high = 6500, size = (nsims,ndata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.std(fakedata, axis = 1)\n",
    "normmeanabsdevs = np.mean(np.abs(fakedata-np.reshape(np.mean(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.7979\n",
    "normmads = np.median(np.abs(fakedata-np.reshape(np.median(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.6745\n",
    "bimidvars = astats.biweight_midvariance(fakedata, axis = 1)\n",
    "iqrs = (np.percentile(fakedata, 75, axis = 1) - np.percentile(fakedata, 25, axis = 1))/1.349\n",
    "tstds = np.array([stats.tstd(fakedata0, limits=(np.percentile(fakedata0, 10),np.percentile(fakedata0, 90))) for fakedata0 in fakedata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected standard deviation: 930\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Standard deviation: 97.8614\n",
      "Average absolute deviation: 89.5477\n",
      "MAD: 40.9750\n",
      "Biweight standard deviation: 92.7675\n",
      "IQR: 15.5951\n",
      "10% Trimmed standard deviation: -283.2803\n",
      "\n",
      "Spread OF ESTIMATORS:\n",
      "Standard deviation: 162.6711\n",
      "Average absolute deviation: 167.9657\n",
      "MAD: 237.1376\n",
      "Biweight standard deviation: 175.5518\n",
      "IQR: 229.9250\n",
      "10% Trimmed standard deviation: 127.1450\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected standard deviation: 930\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.mean(stds - 930):.4f}')\n",
    "print(f'Average absolute deviation: {np.mean(normmeanabsdevs - 930):.4f}')\n",
    "print(f'MAD: {np.mean(normmads - 930):.4f}')\n",
    "print(f'Biweight standard deviation: {np.mean(np.sqrt(bimidvars) - 930):.4f}')\n",
    "print(f'IQR: {np.mean(iqrs - 930):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.mean(tstds - 930):.4f}')\n",
    "print()\n",
    "print(\"Spread OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.std(stds):.4f}')\n",
    "print(f'Average absolute deviation: {np.std(normmeanabsdevs):.4f}')\n",
    "print(f'MAD: {np.std(normmads):.4f}')\n",
    "print(f'Biweight standard deviation: {np.std(np.sqrt(bimidvars)):.4f}')\n",
    "print(f'IQR: {np.std(iqrs):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.std(tstds):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see the IQR outperform the all others in bias with a somewhat higher, but not unreasonable spread, making it the best choice. The MAD takes second place for bias, but the trimmed standard deviation has the lowest spread (at the cost of large bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims=int(1E4)\n",
    "ndata=100\n",
    "foutlier=0.1\n",
    "\n",
    "isoutlier=random.rand(nsims,ndata) < foutlier\n",
    "\n",
    "fakedata=(1-isoutlier)*(random.randn(nsims,ndata)*930.+3150) \\\n",
    "+ (isoutlier)*(random.uniform(low = 0, high = 6500, size = (nsims,ndata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.std(fakedata, axis = 1)\n",
    "normmeanabsdevs = np.mean(np.abs(fakedata-np.reshape(np.mean(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.7979\n",
    "normmads = np.median(np.abs(fakedata-np.reshape(np.median(fakedata, axis = 1), (nsims, 1))), axis = 1)/0.6745\n",
    "bimidvars = astats.biweight_midvariance(fakedata, axis = 1)\n",
    "iqrs = (np.percentile(fakedata, 75, axis = 1) - np.percentile(fakedata, 25, axis = 1))/1.349\n",
    "tstds = np.array([stats.tstd(fakedata0, limits=(np.percentile(fakedata0, 10),np.percentile(fakedata0, 90))) for fakedata0 in fakedata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected standard deviation: 930\n",
      "\n",
      "BIAS OF ESTIMATORS:\n",
      "Standard deviation: 123.9276\n",
      "Average absolute deviation: 105.1157\n",
      "MAD: 64.7894\n",
      "Biweight standard deviation: 115.6268\n",
      "IQR: 57.6636\n",
      "10% Trimmed standard deviation: -254.4174\n",
      "\n",
      "Spread OF ESTIMATORS:\n",
      "Standard deviation: 81.6178\n",
      "Average absolute deviation: 83.2395\n",
      "MAD: 116.7903\n",
      "Biweight standard deviation: 86.4769\n",
      "IQR: 114.9485\n",
      "10% Trimmed standard deviation: 62.1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected standard deviation: 930\")\n",
    "print()\n",
    "print(\"BIAS OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.mean(stds - 930):.4f}')\n",
    "print(f'Average absolute deviation: {np.mean(normmeanabsdevs - 930):.4f}')\n",
    "print(f'MAD: {np.mean(normmads - 930):.4f}')\n",
    "print(f'Biweight standard deviation: {np.mean(np.sqrt(bimidvars) - 930):.4f}')\n",
    "print(f'IQR: {np.mean(iqrs - 930):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.mean(tstds - 930):.4f}')\n",
    "print()\n",
    "print(\"Spread OF ESTIMATORS:\")\n",
    "print(f'Standard deviation: {np.std(stds):.4f}')\n",
    "print(f'Average absolute deviation: {np.std(normmeanabsdevs):.4f}')\n",
    "print(f'MAD: {np.std(normmads):.4f}')\n",
    "print(f'Biweight standard deviation: {np.std(np.sqrt(bimidvars)):.4f}')\n",
    "print(f'IQR: {np.std(iqrs):.4f}')\n",
    "print(f'10% Trimmed standard deviation: {np.std(tstds):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here too, we see the IQR outperform the all others in bias with a somewhat higher, but not unreasonable spread, making it the best choice. The MAD again takes second place for bias, and the trimmed standard deviation has the lowest spread (at the cost of large bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
